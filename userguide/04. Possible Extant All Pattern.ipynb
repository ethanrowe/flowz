{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from tornado import gen\n",
    "from flowz import app\n",
    "from flowz.channels import *\n",
    "\n",
    "from flowz.artifacts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from logging import config as logconf\n",
    "def config_logging(level='DEBUG'):\n",
    "    logconf.dictConfig({\n",
    "            'version': 1,\n",
    "            'loggers': {},\n",
    "            'disable_existing_loggers': 0,\n",
    "            'root': {\n",
    "                'level': level,\n",
    "                'handlers': ['default_handler'],\n",
    "                },\n",
    "            'handlers': {\n",
    "                'default_handler': {\n",
    "                    'class': 'logging.StreamHandler',\n",
    "                    'stream': 'ext://sys.stdout',\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "    )\n",
    "config_logging('WARN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_chans(*chans, **kwargs):\n",
    "    # This is a bit more elaborate than before to resolve artifacts\n",
    "    mode = kwargs.get('mode', 'get')\n",
    "    func = kwargs.get('func', print)\n",
    "    app.Flo([chan.map(lambda y: getattr(y, mode)()).each_ready().map(func) for chan in chans]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible/Extant/All pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another form of joining made possible by the util module is very powerful.  Here is an example reusing the `chan_div_2` and `chan_div_3` from the previous chapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flowz.util import merge_keyed_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "30\n",
      "4\n",
      "60\n",
      "8\n",
      "90\n",
      "10\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "chan_div_2 = IterChannel(KeyedArtifact(i, i) for i in range(1, 13) if i % 2 == 0)\n",
    "chan_div_3 = IterChannel(KeyedArtifact(i, i*10) for i in range(1, 13) if i % 3 == 0)\n",
    "merged = merge_keyed_channels(chan_div_2, chan_div_3)\n",
    "print_chans(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did that do?  If you think carefully about the values produced by the two channels, you will deduce that for each key, it selects the _rightmost_ value with that key.  In other words, the values from both channels make it into the final channel, but if they both provide values for a particular key, the rightmost channel wins.  (Note, in this case, that 6 and 12 are _not_ in the list.)\n",
    "\n",
    "Why is that helpful?  That pattern works very well for creating the Possible/Extant/All pattern that is one main _raisons d' etre_ for the flowz framework in the first place.  Here's how it works...\n",
    "\n",
    "Suppose you have an expensive derivation function.  For giggles and grins, let's say it takes 10 minutes to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "def expensive_deriver(num):\n",
    "    # 10 minutes pass...\n",
    "    return num * 100\n",
    "\n",
    "chan = IterChannel(KeyedArtifact(i, DerivedArtifact(expensive_deriver, i)) for i in range(10))\n",
    "print_chans(chan.tee())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That would have taken 100 minutes.  If your process died 85 minutes in, you would be bummed to have to do it all again.  So, you would like to have a way to write out the results and, in the case of a crash, pick up where you left off.  That's where the pattern comes in.\n",
    "\n",
    "The channel just defined represents all of the __possible__ values, so let's call it that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible = chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we have already written out our data to durable storage.  We can represent that with an array of previously written values (as though we had run for 85 minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 100, 2: 200, 3: 300, 4: 400, 5: 500, 6: 600, 7: 700}\n"
     ]
    }
   ],
   "source": [
    "storage = {num: expensive_deriver(num) for num in range(8)}\n",
    "print(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need an `ExtantArtifact` that gets this data out of storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExampleExtantArtifact(ExtantArtifact):\n",
    "    def __init__(self, num):\n",
    "        super(ExampleExtantArtifact, self).__init__(self.get_me, name='ExampleExtantArtifact')\n",
    "        self.num = num\n",
    "\n",
    "    @gen.coroutine\n",
    "    def get_me(self):\n",
    "        raise gen.Return(storage[self.num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most durable storage mechanisms allow you to determine the keys of your stored items in sorted order, so lets do that and create an __extant__ channel with that order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "keys = sorted(storage.keys())\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "extant = IterChannel(KeyedArtifact(i, ExampleExtantArtifact(i)) for i in sorted(storage.keys()))\n",
    "print_chans(extant.tee())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Now we can combine these two channels into our __all__ channel, preferring the items in the __extant__ channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "all_ = merge_keyed_channels(possible.tee(), extant.tee())\n",
    "print_chans(all_.tee())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK.  Something happened there, but it's not clear exactly what, since it looks like the unadulterated output of the __possible__ channel.  Let's turn logging back on, buid everything again (since all the artifacts have already been derived once, teeing won't be illustrative) and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExampleExtantArtifact<ExampleExtantArtifact> retrieved.\n",
      "ExampleExtantArtifact<ExampleExtantArtifact> retrieved.\n",
      "0\n",
      "ExampleExtantArtifact<ExampleExtantArtifact> retrieved.\n",
      "100\n",
      "200\n",
      "ExampleExtantArtifact<ExampleExtantArtifact> retrieved.\n",
      "300\n",
      "ExampleExtantArtifact<ExampleExtantArtifact> retrieved.\n",
      "400\n",
      "ExampleExtantArtifact<ExampleExtantArtifact> retrieved.\n",
      "500\n",
      "ExampleExtantArtifact<ExampleExtantArtifact> retrieved.\n",
      "600\n",
      "ExampleExtantArtifact<ExampleExtantArtifact> retrieved.\n",
      "700\n",
      "DerivedArtifact<expensive> waiting on sources.\n",
      "DerivedArtifact<expensive> running deriver.\n",
      "DerivedArtifact<expensive> ready.\n",
      "DerivedArtifact<expensive> waiting on sources.\n",
      "DerivedArtifact<expensive> running deriver.\n",
      "DerivedArtifact<expensive> ready.\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "config_logging('INFO')\n",
    "possible = IterChannel(KeyedArtifact(i, DerivedArtifact(expensive_deriver, i, name='expensive')) for i in range(10))\n",
    "extant = IterChannel(KeyedArtifact(i, ExampleExtantArtifact(i)) for i in keys)\n",
    "all_ = merge_keyed_channels(possible, extant)\n",
    "print_chans(all_.tee())\n",
    "config_logging('WARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom!  Notice how the `expensive_deriver()` calls (\"DerivedArtifact&lt;expensive&gt; running deriver.\") are only called twice at the end.  Our code did not have to _consciously_ figure out how much had already been done and _carefully_ make sure that we only call the deriver for the remaining ones.  The lazy evaluation did it all.\n",
    "\n",
    "There is yet one more performance improvement to make here, though.  If we have already written out 8 of our expensively derived data sets, not only do we no longer need to derive and write them out, but we don't even need to read them in!  flowz and the ExtantArtifact class allows to optimize things by _ensuring_ each of the items in the channel, rather than _getting_ them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerivedArtifact<expensive> waiting on sources.\n",
      "DerivedArtifact<expensive> running deriver.\n",
      "DerivedArtifact<expensive> ready.\n",
      "DerivedArtifact<expensive> waiting on sources.\n",
      "DerivedArtifact<expensive> running deriver.\n",
      "DerivedArtifact<expensive> ready.\n"
     ]
    }
   ],
   "source": [
    "config_logging('INFO')\n",
    "possible = IterChannel(KeyedArtifact(i, DerivedArtifact(expensive_deriver, i, name='expensive')) for i in range(10))\n",
    "extant = IterChannel(KeyedArtifact(i, ExampleExtantArtifact(i)) for i in sorted(storage.keys()))\n",
    "all_ = merge_keyed_channels(possible, extant)\n",
    "print_chans(all_.tee(), mode='ensure', func=lambda a: a)\n",
    "config_logging('WARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ensure_ on an `ExtantArtifact` is essentially a no-op just returning True, but it calls the get method on a `DerivedArtifact`.  So we have done the minimal amount needed to get up to date:\n",
    "1. A fast operation (getting the keys) to figure out what has already been written\n",
    "2. The expensive operations for the items remaining to be written\n",
    "\n",
    "All that remains now is that we haven't written this new data.  Let's try that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to write the data, to be passed to a transform() call\n",
    "def data_writing_transform(key, value):\n",
    "    storage[key] = value\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recreate the storage and turn on logging\n",
    "storage = {num: expensive_deriver(num) for num in range(8)}\n",
    "config_logging('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerivedArtifact waiting on sources.\n",
      "DerivedArtifact<expensive> waiting on sources.\n",
      "DerivedArtifact<expensive> running deriver.\n",
      "DerivedArtifact<expensive> ready.\n",
      "DerivedArtifact running deriver.\n",
      "DerivedArtifact ready.\n",
      "DerivedArtifact waiting on sources.\n",
      "DerivedArtifact<expensive> waiting on sources.\n",
      "DerivedArtifact<expensive> running deriver.\n",
      "DerivedArtifact<expensive> ready.\n",
      "DerivedArtifact running deriver.\n",
      "DerivedArtifact ready.\n"
     ]
    }
   ],
   "source": [
    "# Run as though we failed after 85 minutes and are picking up again\n",
    "possible = IterChannel(KeyedArtifact(i, DerivedArtifact(expensive_deriver, i, name='expensive')).transform(data_writing_transform, i) for i in range(10))\n",
    "extant = IterChannel(KeyedArtifact(i, ExampleExtantArtifact(i)) for i in sorted(storage.keys()))\n",
    "all_ = merge_keyed_channels(possible, extant)\n",
    "print_chans(all_.tee(), mode='ensure', func=lambda a: a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's odd.  It shows four deviver calls.  Notice that only two of them, however, have \"&lt;expensive&gt;\" in the log.  It turns out the `transform()` uses a `DerivedArtifact` under the covers, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 100, 2: 200, 3: 300, 4: 400, 5: 500, 6: 600, 7: 700, 8: 800, 9: 900}\n"
     ]
    }
   ],
   "source": [
    "print(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes!  Our storage has been updated.  Now, if we run yet again, nothing should be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "possible = IterChannel(KeyedArtifact(i, DerivedArtifact(expensive_deriver, i, name='expensive')).transform(data_writing_transform, i) for i in range(10))\n",
    "extant = IterChannel(KeyedArtifact(i, ExampleExtantArtifact(i)) for i in sorted(storage.keys()))\n",
    "all = merge_keyed_channels(possible, extant)\n",
    "print_chans(all.tee(), mode='ensure', func=lambda a: a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recreate the storage to not mess up other parts of the notebook when run out of order, and turn off logging\n",
    "storage = {num: expensive_deriver(num) for num in range(8)}\n",
    "config_logging('WARN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
