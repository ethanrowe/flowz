{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from tornado import gen\n",
    "from flowz import app\n",
    "from flowz.channels import *\n",
    "\n",
    "from flowz.artifacts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_chans(*chans, **kwargs):\n",
    "    # This is a bit more elaborate than before to resolve artifacts\n",
    "    mode = kwargs.get('mode', 'get')\n",
    "    func = kwargs.get('func', print)\n",
    "    app.Flo([chan.map(lambda y: getattr(y, mode)()).each_ready().map(func) for chan in chans]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KeyedArtifacts and Joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyedArtifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A `KeyedArtifact` is an artifact that, in addition to wrapping another artifact, exposes a key associated with that artifact's value.  That simple idea unlocks some powerful capabilities from flowz, and it is central to its most effective uses, particularly when you know the key _ahead_ of knowing the values.\n",
    "\n",
    "For instance, suppose you have bunch of daily data stored in an S3 bucket using keys that include somewhere in their pattern the relevant date of the data.  You could do one boto3 query to find all the S3 keys that exist, ferret out the date from those S3 keys, and construct for each date a `KeyedArtifact` with that date as its key, wrapping an `ExtantArtifact` prepped with the full S3 key.  You would then have, at the ready, an artifact that could be lazily fetched if its value were needed, and the date key on the artifact would help you to determine later whether you need to read it in.  (This will become clearer later in this chapter.)\n",
    "\n",
    "For now, here is a quick demonstration of finding the key by attribute and by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key = 0 ; [0] = 0 ; [1] = KeyedArtifact\n",
      "key = 1 ; [0] = 1 ; [1] = KeyedArtifact\n",
      "key = 2 ; [0] = 2 ; [1] = KeyedArtifact\n",
      "----\n",
      "0\n",
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "def lame_deriver(num):\n",
    "    return num * 100\n",
    "\n",
    "chan = IterChannel(KeyedArtifact(i, DerivedArtifact(lame_deriver, i)) for i in range(3))\n",
    "tee = chan.tee()\n",
    "app.Flo([chan.map(lambda a: print('key =', a.key, '; [0] =', a[0], '; [1] =', a[1]))]).run()\n",
    "print('----')\n",
    "print_chans(tee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing `KeyedArtifacts` make possible is joining between two channels using the keys of the items in each channel.\n",
    "\n",
    "flowz provides a `CoGroupChannel` that joins two channels, grouping the items by their keys in a very \"cover all bases\" approach that is reminiscent of a \"full outer join\" in SQL.  Its default approach can be difficult to understand (though it is documented well in the docstring for `CoGroupChannel`), but it can be easily specialized.\n",
    "\n",
    "A very useful specialization is supplied by the `flowz.util.channel_inner_join(a, b)` function, which will join together the items in each channel that have equivalent keys.\n",
    "\n",
    "> NOTE: It is important that the channels to be joined already present their objects in the relevant \"sort\" order for their keys.  While sorting of channels is technically possible, it is not (yet) exposed as a first-class operation for various design reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with two channels, defined with keys that are divisible by 2 and 3, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chan_div_2 = IterChannel(KeyedArtifact(i, i) for i in range(1, 13) if i % 2 == 0)\n",
    "chan_div_3 = IterChannel(KeyedArtifact(i, i*10) for i in range(1, 13) if i % 3 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: Those `KeyedArtifacts` use a bit of a trick where a scalar value is passed in as the artifact.  This is not generally done in practice, and it is only _mostly_ supported, but it is useful for this illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "----\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print_chans(chan_div_2.tee())\n",
    "print('----')\n",
    "print_chans(chan_div_3.tee())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal `print_chans()` used in this guide just prints the fully resolved values of the artifacts, but you can visually infer the keys from the values.\n",
    "\n",
    "This piece of code, however, shows their structures a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key = 2 ; value = 2\n",
      "key = 4 ; value = 4\n",
      "key = 6 ; value = 6\n",
      "key = 8 ; value = 8\n",
      "key = 10 ; value = 10\n",
      "key = 12 ; value = 12\n",
      "----\n",
      "key = 3 ; value = 30\n",
      "key = 6 ; value = 60\n",
      "key = 9 ; value = 90\n",
      "key = 12 ; value = 120\n"
     ]
    }
   ],
   "source": [
    "app.Flo([chan_div_2.tee().map(lambda (k, a): print('key =', k, '; value =', a.value))]).run()\n",
    "print('----')\n",
    "app.Flo([chan_div_3.tee().map(lambda (k, a): print('key =', k, '; value =', a.value))]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can \"cogroup\" the channels and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<flowz.artifacts.KeyedArtifact object at 0x109c5fa90>, None)\n",
      "(<flowz.artifacts.KeyedArtifact object at 0x109c5fa90>, <flowz.artifacts.KeyedArtifact object at 0x109b80850>)\n",
      "(<flowz.artifacts.KeyedArtifact object at 0x109c5fb50>, <flowz.artifacts.KeyedArtifact object at 0x109b80850>)\n",
      "(<flowz.artifacts.KeyedArtifact object at 0x109c52d50>, <flowz.artifacts.KeyedArtifact object at 0x109c48f10>)\n",
      "(<flowz.artifacts.KeyedArtifact object at 0x109c5fc90>, <flowz.artifacts.KeyedArtifact object at 0x109c48f10>)\n",
      "(<flowz.artifacts.KeyedArtifact object at 0x109c5fc90>, <flowz.artifacts.KeyedArtifact object at 0x109b80610>)\n",
      "(<flowz.artifacts.KeyedArtifact object at 0x109c5fcd0>, <flowz.artifacts.KeyedArtifact object at 0x109b80610>)\n",
      "(<flowz.artifacts.KeyedArtifact object at 0x109c5fd90>, <flowz.artifacts.KeyedArtifact object at 0x109c48ad0>)\n"
     ]
    }
   ],
   "source": [
    "cogroup = chan_div_2.tee().cogroup(chan_div_3.tee())\n",
    "app.Flo([cogroup.tee().map(print)]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that cogrouping produces tuples with artifacts from the each of the two channels.  If there were N channels involved, it would be an N-tuple.  Curiously, though, the first tuple has a None from the second channel, and various artifacts appear multiple times. This code will elucidate it further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2, 2), None)\n",
      "((2, 2), (3, 30))\n",
      "((4, 4), (3, 30))\n",
      "((6, 6), (6, 60))\n",
      "((8, 8), (6, 60))\n",
      "((8, 8), (9, 90))\n",
      "((10, 10), (9, 90))\n",
      "((12, 12), (12, 120))\n"
     ]
    }
   ],
   "source": [
    "app.Flo([cogroup.tee().map(lambda (a1, a2): print(((a1.key, a1.value),(a2.key,a2.value) if a2 else None)))]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the \"full outer join-ish\" sort of grouping that cogroup does.  (See the `CoGroupChannel` docstring for more information.)\n",
    "\n",
    ">A full outer join would have each element present from each channel, but `None` in positions where a particular item doesn't have a match.  For instance, the second element above would be `(None, (3, 30))`.  This \"cogrouping\" essentially does the same thing, but, instead of putting `None`, it _reminds_ you what the last good value was from the other side.\n",
    "\n",
    "> Why might that reminding be useful?  Suppose the keys were timestamps of two independent events that happen frequently, but randomly during the day.  You might never have two equivalent timestamps, but the cogrouping would allow you to figure out easily every point in time at when the \"latest pair of values\" changed.\n",
    "\n",
    "We can constrain it with a filter to only those where the keys are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6, 6), (6, 60))\n",
      "((12, 12), (12, 120))\n"
     ]
    }
   ],
   "source": [
    "chan_div_6 = cogroup.tee().filter(lambda (a, b): a is not None and b is not None and a[0] == b[0])\n",
    "app.Flo([chan_div_6.tee().map(lambda (a1, a2): print(((a1.key, a1.value),(a2.key,a2.value) if a2 else None)))]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!  And because that is so convenient, there is a function to do that for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from flowz.util import channel_inner_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6, 6), (6, 60))\n",
      "((12, 12), (12, 120))\n"
     ]
    }
   ],
   "source": [
    "chan_div_6 = channel_inner_join(chan_div_2.tee(), chan_div_3.tee())\n",
    "app.Flo([chan_div_6.tee().map(lambda (a1, a2): print(((a1.key, a1.value),(a2.key,a2.value) if a2 else None)))]).run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
