{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from tornado import gen\n",
    "from flowz import app\n",
    "from flowz.channels import *\n",
    "\n",
    "from flowz.artifacts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_chans(*chans):\n",
    "    app.Flo([chan.map(print) for chan in chans]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a function that calculates some value for a given index, which we will think of as \"days from the beginning of the year\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 113)\n",
      "(1, 185)\n",
      "(2, 177)\n",
      "(3, 125)\n",
      "(4, 150)\n",
      "(5, 145)\n",
      "(6, 165)\n",
      "(7, 179)\n",
      "(8, 109)\n",
      "(9, 102)\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "chan = IterChannel((i, random.randint(100, 200)) for i in range(10))\n",
    "print_chans(chan.tee())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On any given day, you may want to know not just the value on that day, but all of the historical values as well.  And it would be lovely to be able to get that in one data structure, especially if stored in cloud storage, rather than having to iterate over a channel each time.\n",
    "\n",
    "flowz provides an incremental assembly facility that makes this relatively easy to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flowz.util import incremental_assembly, NO_VALUE\n",
    "\n",
    "# NO_VALUE is a special value defined for incremental_assembly() that indicates the start of assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 113),)\n",
      "((1, 185), (0, 113))\n",
      "((2, 177), (1, 185), (0, 113))\n",
      "((3, 125), (2, 177), (1, 185), (0, 113))\n",
      "((4, 150), (3, 125), (2, 177), (1, 185), (0, 113))\n",
      "((5, 145), (4, 150), (3, 125), (2, 177), (1, 185), (0, 113))\n",
      "((6, 165), (5, 145), (4, 150), (3, 125), (2, 177), (1, 185), (0, 113))\n",
      "((7, 179), (6, 165), (5, 145), (4, 150), (3, 125), (2, 177), (1, 185), (0, 113))\n",
      "((8, 109), (7, 179), (6, 165), (5, 145), (4, 150), (3, 125), (2, 177), (1, 185), (0, 113))\n",
      "((9, 102), (8, 109), (7, 179), (6, 165), (5, 145), (4, 150), (3, 125), (2, 177), (1, 185), (0, 113))\n"
     ]
    }
   ],
   "source": [
    "def prepend_assembler(new, old):\n",
    "    \"\"\"\n",
    "    A simple assembler that prepends new data at the beginning of the tuple of old data.\n",
    "    \"\"\"\n",
    "    if old is NO_VALUE:\n",
    "        return (new,)\n",
    "    else:\n",
    "        return (new,) + old\n",
    "\n",
    "dest = IterChannel([])\n",
    "out = incremental_assembly(chan.tee(), dest.tee(), prepend_assembler)\n",
    "print_chans(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That is an admittedly simple example of incremental assembly.  In practice, the indices are likely to be dates, and the data might be pandas series or dataframes that get concatenated together.  Nonetheless, the assemblers remain easy to write, and the infrastructure does a reliable job of passing on to the assembler the prior assembled data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
