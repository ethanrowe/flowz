{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from tornado import gen\n",
    "from flowz import app\n",
    "from flowz.channels import *\n",
    "from flowz.artifacts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from logging import config as logconf\n",
    "def config_logging(level='DEBUG'):\n",
    "    logconf.dictConfig({\n",
    "            'version': 1,\n",
    "            'loggers': {},\n",
    "            'disable_existing_loggers': 0,\n",
    "            'root': {\n",
    "                'level': level,\n",
    "                'handlers': ['default_handler'],\n",
    "                },\n",
    "            'handlers': {\n",
    "                'default_handler': {\n",
    "                    'class': 'logging.StreamHandler',\n",
    "                    'stream': 'ext://sys.stdout',\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "    )\n",
    "config_logging('DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_chans(*chans):\n",
    "    # This is a bit more elaborate than before to resolve artifacts\n",
    "    app.Flo([chan.map(lambda y: getattr(y, 'get')()).each_ready().map(print) for chan in chans]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If channels only used sources like lists and dictionaries already in memory, they would have little value. The true values comes when getting data from external sources or heavy computations that take time.  In such an environment, accessing the data asynchronously and concurrently -- and even \"out of order\" in some cases -- can lead to nice performance benefits, and possibly more elegant code.\n",
    "\n",
    "A significant boost in unlocking that asynchrony is artifacts. Artifacts are objects that know how to retrieve, compute, or transform their data, but don't necessarily do it right away.  They delay getting the data until requested to do so, and then they use the tornado/futures infrastructure to get their data asynchronously.  Once ready, their data is available to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtantArtifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `ExtantArtifact` is an artifact that represents data that is known to exist, and it uses a tornado coroutine to get its data.  It is particularly suitable for fetching data via existing asynchronous mechanisms, like `httpclient.AsyncHTTPClient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# An ExtantArtifact that will be used here and elsewhere in the guide\n",
    "class GuideExtantArtifact(ExtantArtifact):\n",
    "    def __init__(self, num):\n",
    "        super(GuideExtantArtifact, self).__init__(self.get_me, name='GuideExtantArtifact')\n",
    "        self.num = num\n",
    "\n",
    "    @gen.coroutine\n",
    "    def get_me(self):\n",
    "        # O, pardon! since a crooked figure may attest in little place a million;\n",
    "        # On your imaginary forces work... Piece out our imperfections with your thoughts;\n",
    "        # Think when we talk of horses, that you see them printing their proud hoofs in the receiving earth;\n",
    "        # For 'tis your thoughts that now must deck our kings...\n",
    "        # (in other words, pretend this got some impressive data asynchronously)\n",
    "        raise gen.Return((self.num, self.num * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GuideExtantArtifact<GuideExtantArtifact> starting get\n",
      "GuideExtantArtifact<GuideExtantArtifact> retrieved.\n",
      "GuideExtantArtifact<GuideExtantArtifact> starting get\n",
      "GuideExtantArtifact<GuideExtantArtifact> retrieved.\n",
      "(0, 0)\n",
      "GuideExtantArtifact<GuideExtantArtifact> starting get\n",
      "GuideExtantArtifact<GuideExtantArtifact> retrieved.\n",
      "(1, 100)\n",
      "(2, 200)\n"
     ]
    }
   ],
   "source": [
    "chan = IterChannel([GuideExtantArtifact(i) for i in range(3)])\n",
    "print_chans(chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise!  Artifacts have logging built into them.  In the case of `ExtantArtifact`, it logs before calling the getter (which then yields) and after it has completed the retrieval of the data.  (These log messages are a blend of DEBUG and INFO level, so the detail will vary at times in this guide.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DerivedArtifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DerivedArtifact` is an artifact that uses a normal synchronous function as a deriver of its data.  That function will be passed any number of \"sources\", and flowz will make sure that all of the sources have been fully resolved before being passed as parameters.  For instance, if the sources are artifacts, they will be resolved to their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerivedArtifact starting get\n",
      "DerivedArtifact waiting on sources.\n",
      "DerivedArtifact running deriver.\n",
      "DerivedArtifact ready.\n",
      "DerivedArtifact starting get\n",
      "DerivedArtifact waiting on sources.\n",
      "DerivedArtifact running deriver.\n",
      "DerivedArtifact ready.\n",
      "(0, 0)\n",
      "DerivedArtifact starting get\n",
      "DerivedArtifact waiting on sources.\n",
      "DerivedArtifact running deriver.\n",
      "DerivedArtifact ready.\n",
      "(1, -10)\n",
      "(2, -20)\n"
     ]
    }
   ],
   "source": [
    "def lame_deriver(num):\n",
    "    return (num, -10 * num)\n",
    "\n",
    "chan = IterChannel(DerivedArtifact(lame_deriver, i) for i in range(3))\n",
    "print_chans(chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again we see logging, but a bit more.  Before the deriver is called, flowz first makes sure that each one of the sources is resolved.  Then the deriver is called -- synchronously -- and the results are ready.\n",
    "\n",
    "Note above that there are two \"ready\" messages before the first value is actually printed.  That, again, is an indicator of the asychronous processing of the channels.\n",
    "\n",
    "In practice, `DerivedArtifacts` are used to gather and transform data that began with `ExtantArtifacts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerivedArtifact starting get\n",
      "DerivedArtifact waiting on sources.\n",
      "GuideExtantArtifact<GuideExtantArtifact> starting get\n",
      "GuideExtantArtifact<GuideExtantArtifact> retrieved.\n",
      "DerivedArtifact running deriver.\n",
      "DerivedArtifact ready.\n",
      "DerivedArtifact starting get\n",
      "DerivedArtifact waiting on sources.\n",
      "GuideExtantArtifact<GuideExtantArtifact> starting get\n",
      "GuideExtantArtifact<GuideExtantArtifact> retrieved.\n",
      "DerivedArtifact running deriver.\n",
      "DerivedArtifact ready.\n",
      "(0, 0)\n",
      "DerivedArtifact starting get\n",
      "DerivedArtifact waiting on sources.\n",
      "GuideExtantArtifact<GuideExtantArtifact> starting get\n",
      "GuideExtantArtifact<GuideExtantArtifact> retrieved.\n",
      "DerivedArtifact running deriver.\n",
      "DerivedArtifact ready.\n",
      "(1, -10)\n",
      "(2, -20)\n"
     ]
    }
   ],
   "source": [
    "def not_as_lame_deriver(val):\n",
    "    num, extant_val = val\n",
    "    return (num, extant_val / -10)\n",
    "\n",
    "chan = IterChannel(GuideExtantArtifact(i) for i in range(3)).map(lambda a: DerivedArtifact(not_as_lame_deriver, a))\n",
    "print_chans(chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see that the firing of each `DerivedArtifact` caused its source to be resolved, which meant that its wrapped `GuideExtantArtifact` retrieved its value.  Only after that was the result (a tuple) passed into the deriver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThreadedDerivedArtifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `ThreadedDerivedArtifact` is just like a `DerivedArtifact`, but it is passed a `concurrent.futures.ThreadPoolExecutor` on which it will run.\n",
    "\n",
    "1. Some things are IO-bound and thus quite amenable to the async IO pattern around which tornado is built. But they aren't implemented in terms of async IO. In such cases, you can get good results by pushing the blocking IO onto a thread pool executor, which this enables. The individual threads can block on the synchronous IO, but the main IOLoop continues on its merry way all the while. So if you're dealing with synchronous IO-bound clients, put 'em in here.  (NOTE: boto and boto3 are _prime_ examples of this.)\n",
    "\n",
    "2. Some routines are pretty hoggy in terms of computation, and they'll starve the IOLoop unless you take steps to offload them. In such cases, getting them onto a thread pool executor (and a shallow pool, at that) can be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadedDerivedArtifact created (None).\n",
      "ThreadedDerivedArtifact created (None).\n",
      "ThreadedDerivedArtifact created (None).\n",
      "ThreadedDerivedArtifact starting get\n",
      "ThreadedDerivedArtifact waiting on sources.\n",
      "ThreadedDerivedArtifact running deriver on executor.\n",
      "ThreadedDerivedArtifact starting get\n",
      "ThreadedDerivedArtifact waiting on sources.\n",
      "ThreadedDerivedArtifact running deriver on executor.\n",
      "ThreadedDerivedArtifact ready.\n",
      "ThreadedDerivedArtifact ready.\n",
      "(0, 0)\n",
      "ThreadedDerivedArtifact starting get\n",
      "ThreadedDerivedArtifact waiting on sources.\n",
      "(1, -10)ThreadedDerivedArtifact running deriver on executor.\n",
      "\n",
      "ThreadedDerivedArtifact ready.\n",
      "(2, -20)\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "executor = futures.ThreadPoolExecutor(1)\n",
    "chan = IterChannel(ThreadedDerivedArtifact(executor, lame_deriver, i) for i in range(3))\n",
    "print_chans(chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Okay, no more logging!\n",
    "config_logging('WARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformedArtifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TransformedArtifact` wraps another artifact and transforms its value.  Its not that different from a `DerivedArtifact`.  One advantage that it has -- inherited from its superclass `WrappedArtifact`, which is rarely used directly -- is that indexing and attribute calls are passed on through to the underlying artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(1, -10)\n",
      "(2, -20)\n"
     ]
    }
   ],
   "source": [
    "chan = IterChannel(TransformedArtifact(GuideExtantArtifact(i), transformer=not_as_lame_deriver) for i in range(3))\n",
    "print_chans(chan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
